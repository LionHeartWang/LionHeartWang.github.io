<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大数据 | Workspace of LionHeart]]></title>
  <link href="http://lionheartwang.github.io/blog/categories/大数据/atom.xml" rel="self"/>
  <link href="http://lionheartwang.github.io/"/>
  <updated>2018-02-08T10:40:21+08:00</updated>
  <id>http://lionheartwang.github.io/</id>
  <author>
    <name><![CDATA[Wang Yiguang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[搭建Ray集群步骤]]></title>
    <link href="http://lionheartwang.github.io/blog/2018/02/08/da-jian-rayji-qun-bu-zou/"/>
    <updated>2018-02-08T10:29:16+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2018/02/08/da-jian-rayji-qun-bu-zou</id>
    <content type="html"><![CDATA[<p>本文介绍如何搭建Ray 0.3集群环境。</p>

<p>可参考官方文档：</p>

<ul>
<li><a href="https://ray.readthedocs.io/en/latest/using-ray-on-a-cluster.html">https://ray.readthedocs.io/en/latest/using-ray-on-a-cluster.html</a></li>
</ul>


<!-- More -->


<h2>安装Ray</h2>

<p>首先在每台机器上安装如下组件。</p>

<h3>安装Anaconda</h3>

<p>首先安装Anaconda，下载：</p>

<ul>
<li>Anaconda2-4.3.0-Linux-x86_64.sh</li>
</ul>


<p>按提示执行安装即可。</p>

<h3>安装Ray依赖</h3>

<p>ray依赖如下库：</p>

<ul>
<li>six (>=1.0.0)</li>
<li>redis</li>
<li>pytest</li>
<li>psutil</li>
<li>numpy</li>
<li>funcsigs</li>
<li>flatbuffers</li>
<li>colorama</li>
<li>cloudpickle (==0.5.2)</li>
<li>click</li>
</ul>


<p>注意：</p>

<ul>
<li>如果机器环境通pip源则直接pip install即可。</li>
<li>如果不通可以在 <a href="https://pypi.python.org/pypi/ray/0.3.0">https://pypi.python.org/pypi/ray/0.3.0</a> 下载.whl包后上传到机器pip本地安装。</li>
</ul>


<h3>安装Ray 0.3</h3>

<p>如果环境通pip源</p>

<pre><code class="bash">$ pip install ray
</code></pre>

<p>如果不通则在 <a href="https://pypi.python.org/pypi/ray/0.3.0">https://pypi.python.org/pypi/ray/0.3.0</a> 下载 ：</p>

<ul>
<li>ray-0.3.0-cp27-cp27mu-manylinux1_x86_64.whl</li>
</ul>


<p>然后执行：</p>

<pre><code class="bash">$ pip install ray-0.3.0-cp27-cp27mu-manylinux1_x86_64.whl
</code></pre>

<h2>搭建集群</h2>

<p>假设集群IP如下：</p>

<pre><code>192.168.0.1
192.168.0.2
192.168.0.3
192.168.0.4
192.168.0.5
192.168.0.6
192.168.0.7
192.168.0.8
192.168.0.9
192.168.0.10
</code></pre>

<p>搭建集群环境如下：</p>

<h3>启动Head节点</h3>

<p>选一个节点作为head节点，例如IP为：</p>

<pre><code>192.168.0.1
</code></pre>

<p>在head节点执行：</p>

<pre><code class="bash">ray start --head --node-ip-address 192.168.0.1 --redis-port=6379
</code></pre>

<p>执行后会启动主节点相关的服务。</p>

<h3>启动Worker节点</h3>

<p>Worker节点IP为：</p>

<pre><code class="bash">192.168.0.2
192.168.0.3
192.168.0.4
192.168.0.5
192.168.0.6
192.168.0.7
192.168.0.8
192.168.0.9
192.168.0.10
</code></pre>

<p>在每台Worker节点上执行：</p>

<pre><code class="bash">ray start --redis-address :6379 192.168.0.x --num-cpus 10
</code></pre>

<p>执行后会启动Worker节点相关服务，其中：</p>

<ul>
<li>192.168.0.x 为对应节点IP</li>
<li>num-cpu选项可以用于设置每台节点可用的cpu数，默认为机器总的cpu数。</li>
</ul>


<h3>停止集群</h3>

<p>Head节点与Worker节点服务的停止命令相同，执行：</p>

<pre><code>ray stop
</code></pre>

<h2>连接集群</h2>

<p>使用如下方法建立连接：</p>

<pre><code class="python">import ray

ray.init(redis_address="11.184.187.19:6379")
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Fuse挂载HDFS到本地目录方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/11/14/gua-zai-hdfsdao-ben-di-mu-lu-fang-fa/"/>
    <updated>2017-11-14T00:10:27+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/11/14/gua-zai-hdfsdao-ben-di-mu-lu-fang-fa</id>
    <content type="html"><![CDATA[<p>网上关于挂载HDFS到本地的介绍大多基于较早版本的Hadoop。
本文以Hadoop-2.8.0为例，介绍通过Fuse挂载HDFS到本地的方法。</p>

<!--more-->


<h2>安装Fuse</h2>

<p>对每台节点，执行如下命令一键安装</p>

<pre><code class="bash">sudo yum -y install fuse fuse-libs
</code></pre>

<h2>编译fuse-dfs工具</h2>

<p>下载hadoop-2.8.0源码，解压编译</p>

<pre><code class="bash">tar zxvf hadoop-2.8.0.tar.gz
cd hadoop-2.8.0
mvn package -Drequire.fuse=true -DskipTests -Dmaven.javadoc.skip=true -Dtar
</code></pre>

<p>编译后会生成fuse_dfs的可执行文件，位于</p>

<blockquote><p>./hadoop-hdfs-project/hadoop-hdfs-native-client/target/main/native/fuse-dfs/fuse_dfs</p></blockquote>

<p>另外会生成一个对该可执行程序的封装脚本，位于</p>

<blockquote><p>./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_dfs_wrapper.sh</p></blockquote>

<h2>配置环境变量</h2>

<p>可以为fuse_dfs_wrapper.sh建立软链接到当前目录方便后续使用。</p>

<pre><code class="bash">ln -s /&lt;Hadoop源码路径&gt;/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_dfs_wrapper.sh .
</code></pre>

<p>编辑fuse_dfs_wrapper.sh内容，有一些需要根据具体情况修改：</p>

<pre><code class="bash">HADOOP_HOME=/path/to/your/hadoop
HADOOP_PREFIX=/path/to/your/hadoop/src/

export FUSEDFS_PATH="$HADOOP_PREFIX/hadoop-hdfs-project/hadoop-hdfs-native-client/target/main/native/fuse-dfs"
export LIBHDFS_PATH="$HADOOP_PREFIX/hadoop-hdfs-project/hadoop-hdfs-native-client/target/native/target/usr/local/lib"
HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

if [ "$OS_ARCH" = "" ]; then
  export OS_ARCH=amd64
fi

# 这里需要替换为JDK的安装路径
JAVA_HOME=/home/yiguang.wyg/tools/jdk1.8.0_121

if [ "$LD_LIBRARY_PATH" = "" ]; then
  export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/$OS_ARCH/server:/usr/local/lib
fi

JARS=`find "$HADOOP_PREFIX/hadoop-hdfs-project" -name "*.jar" | xargs`
for jar in $JARS; do
  CLASSPATH=$jar:$CLASSPATH
done

JARS=`find "$HADOOP_PREFIX/hadoop-client" -name "*.jar" | xargs`
for jar in $JARS; do
  CLASSPATH=$jar:$CLASSPATH
done

export CLASSPATH=$HADOOP_CONF_DIR:$CLASSPATH
export PATH=$FUSEDFS_PATH:$PATH
export LD_LIBRARY_PATH=$LIBHDFS_PATH:$JAVA_HOME/jre/lib/$OS_ARCH/server:$LD_LIBRARY_PATH

fuse_dfs "$@"
</code></pre>

<p>重点需要配置好HADOOP_HOME和HADOOP_PREFIX，分别为hadoop安装路径和hadoop源码路径。</p>

<h2>挂载HDFS</h2>

<p>挂载HDFS之前需要确保HDFS已经启动。</p>

<p>创建挂载目录</p>

<pre><code class="bash">sudo mkdir /mnt/hdfs
</code></pre>

<p>执行：</p>

<pre><code class="bash">sudo sh fuse_dfs_wrapper.sh hdfs://&lt;hdfs路径&gt; /mnt/hdfs
</code></pre>

<p>输出：</p>

<blockquote><p>INFO /&hellip;/hadoop-2.8.0-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_options.c:164 Adding FUSE arg /mnt/hdfs</p></blockquote>

<p>进入挂载目录，如果能访问到HDFS中的内容，说明挂载成功。
<code>
cd /mnt/hdfs
ls
</code></p>

<p>挂载成功后，就可以将HDFS当做本地路径使用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ZooKeeper安装使用指南]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/01/20/zookeeperan-zhuang-shi-yong-zhi-nan/"/>
    <updated>2017-01-20T15:56:22+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/01/20/zookeeperan-zhuang-shi-yong-zhi-nan</id>
    <content type="html"><![CDATA[<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务。</p>

<p>作为分布式应用提供一致性服务的软件，ZooKeeper 封装了易错的关键服务，提供简单高效、功能稳定接口给用户</p>

<p>本文介绍 ZooKeeper 的配置方法和客户端使用方法。</p>

<!--more-->


<h2>ZooKeeper 安装</h2>

<p>以ZooKeeper 3.4.8为例，下载 <a href="http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.8/">ZooKeeper 3.4.8</a>
下载解压后配置conf/zoo.cfg，配置clientPort，dataDir等。
示例配置：</p>

<pre><code class="bash"># The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial synchronization phase can take
initLimit=10
# The number of ticks that can pass between sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored. do not use /tmp for storage, /tmp here is just example sakes.
dataDir=/tmp/zookeeper
# the port at which the clients will connect
clientPort=2181
</code></pre>

<h2>ZooKeeper 使用</h2>

<p>配置好Zk后需要先启动ZkServer，然后可以用Zk Client直接以命令行的方式操作Zk。</p>

<h3>Server端</h3>

<p>配置好后启动zk：</p>

<pre><code class="bash">$sh bin/zkServer.sh start &gt; zookeeper.out
</code></pre>

<h3>Client端</h3>

<p>ZooKeeper客户端的使用非常简单，启动：</p>

<pre><code class="bash"># ip和端口根据启动情况修改
$sh bin/zkCli.sh -server 127.0.0.1:2181
</code></pre>

<p>之后可以用ls、delete、get等命令查询或修改各ZK节点的值。命令帮助如下：</p>

<pre><code>ZooKeeper -server host:port cmd args
    connect host:port
    get path [watch]
    ls path [watch]
    set path data [version]
    rmr path
    delquota [-n|-b] path
    quit
    printwatches on|off
    create [-s] [-e] path data acl
    stat path [watch]
    close
    ls2 path [watch]
    history
    listquota path
    setAcl path acl
    getAcl path
    sync path
    redo cmdno
    addauth scheme auth
    delete path [version]
    setquota -n|-b val path
</code></pre>

<h2>ZooKeeper API</h2>

<p>除了通过客户端操作ZooKeeper，还可以调用ZooKeeper提供的API操作ZooKeeper的节点。</p>

<p>这里以ZooKeeper 3.4.5为例，介绍常用的几个Java API。</p>

<h3>建立连接</h3>

<p>在应用程序中使用Zk需要先创建ZooKeeper对象，后续的操作都是基于该对象进行的。</p>

<pre><code class="java">public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) throws IOException  
</code></pre>

<p>参数说明：</p>

<ul>
<li>connectString： zookeeper server列表, 以逗号隔开。ZooKeeper对象初始化后, 将从列表中选择一个server, 并尝试建立连接。如果失败,则会从剩余项中选择并再次尝试建立连接。</li>
<li>sessionTimeout：指定连接的超时时间.</li>
<li>watcher： 事件回调接口。</li>
</ul>


<h3>创建/删除znode</h3>

<p>ZooKeeper对象的create/delete方法用于创建/删除 znode。如果该node存在, 则返回该node的状态信息, 否则返回null。</p>

<pre><code class="java">public String create(String path, byte[] data, List acl, CreateMode createMode); 
public void delete(final String path, int version);  
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>data：与znode关联的数据。</li>
<li>acl：指定权限信息</li>
<li>createMode：指定znode类型，按持久化节点与临时节点，以及自动编号节点与非自动编号节点两个维度划分，共4类。</li>
<li>version：指定要更新的数据的版本, 如果version和真实的版本不同, 更新操作将失败.。指定version为-1则忽略版本检查。</li>
</ul>


<h3>获取子znode列表</h3>

<p>ZooKeeper对象的getChildren方法用于获取子node列表。</p>

<pre><code class="java">public List getChildren(String path, boolean watch); 
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>watch参数用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
</ul>


<h3>判断znode是否存在</h3>

<p>ZooKeeper对象的exists方法用于判断指定znode是否存在。如果该node存在, 则返回该node的状态信息, 否则返回null。</p>

<pre><code class="java">public Stat exists(String path, boolean watch);  
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>watch：用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
</ul>


<h3>获取/更新znode数据</h3>

<p>ZooKeeper对象的getData/setData方法用于获取/更新 znode关联的数据。</p>

<pre><code class="java">public byte[] getData(String path, boolean watch, Stat stat);  
public Stat setData(final String path, byte data[], int version); 
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>stat：传出参数, getData方法会将path node的状态信息设置到该参数中。</li>
<li>data：与znode关联的数据。</li>
<li>watch：用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
<li>version：指定要更新的数据的版本, 如果version和真实的版本不同, 更新操作将失败.。指定version为-1则忽略版本检查。</li>
</ul>


<p>更全的API介绍参考 ZooKeeper 3.4.5 API</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark Core 消息队列机制]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/11/28/spark-core-message-queue-mechanism/"/>
    <updated>2016-11-28T14:31:03+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/11/28/spark-core-message-queue-mechanism</id>
    <content type="html"><![CDATA[<p>本文介绍Spark中的消息队列机制，首先SparkListenerEvent，SparkListener和SparkListenerBus等基本数据结构实现。</p>

<p>重点介绍了异步消息总线LiveListenerBus的实现。随后介绍了Spark消息队列的整体工作流程。</p>

<!--more-->


<h2>SparkListenerEvent</h2>

<p>Spark中的消息由SparkListenerEvent表示。其本身定义只是一个接口：</p>

<pre><code class="scala">trait SparkListenerEvent {
  /* Whether output this event to the event log */
  protected[spark] def logEvent: Boolean = true
}
</code></pre>

<p>SparkListenerEvent有多个具体的实现，每种实现代表了Spark运行过程中的一种事件。</p>

<ul>
<li>SparkListenerStageSubmitted</li>
<li>SparkListenerStageCompleted</li>
<li>SparkListenerTaskStart</li>
<li>SparkListenerTaskGettingResult</li>
<li>SparkListenerTaskEnd</li>
<li>SparkListenerJobStart</li>
<li>SparkListenerJobEnd</li>
<li>SparkListenerEnvironmentUpdate</li>
<li>SparkListenerBlockManagerAdded</li>
<li>SparkListenerBlockManagerRemoved</li>
<li>SparkListenerUnpersistRDD</li>
<li>SparkListenerExecutorAdded</li>
<li>SparkListenerExecutorRemoved</li>
<li>SparkListenerBlockUpdated</li>
<li>SparkListenerExecutorMetricsUpdate</li>
<li>SparkListenerApplicationStart</li>
<li>SparkListenerApplicationEnd</li>
<li>SparkListenerLogStart</li>
</ul>


<p>根据名称可以知道每一种事件代表的含义。</p>

<h2>SparkListener</h2>

<p>SparkListeners负责监听SparkListenerEvents。</p>

<p>所有Spark消息SparkListenerEvents 被异步的发送给已经注册过的SparkListeners。</p>

<p>SparkListenerInterface定义了SparkListener的接口：</p>

<ul>
<li>onStageCompleted</li>
<li>onStageSubmitted</li>
<li>onTaskStart</li>
<li>onTaskGettingResult</li>
<li>onTaskEnd</li>
<li>onJobStart</li>
<li>onJobEnd</li>
<li>onEnvironmentUpdate</li>
<li>onBlockManagerAdded</li>
<li>onBlockManagerRemoved</li>
<li>onUnpersistRDD</li>
<li>onApplicationStart</li>
<li>onApplicationEnd</li>
<li>onExecutorMetricsUpdate</li>
<li>onExecutorAdded</li>
<li>onExecutorRemoved</li>
<li>onBlockUpdated</li>
<li>onOtherEvent</li>
</ul>


<p>根据名称可以知道每一个方法是对应事件消息的响应函数。SparkListener的实现：</p>

<pre><code class="scala">abstract class SparkListener extends SparkListenerInterface {
  override def onStageCompleted(stageCompleted: SparkListenerStageCompleted): Unit = { }
  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = { }
  override def onTaskStart(taskStart: SparkListenerTaskStart): Unit = { }
  override def onTaskGettingResult(taskGettingResult: SparkListenerTaskGettingResult): Unit = { }
  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = { }
  override def onJobStart(jobStart: SparkListenerJobStart): Unit = { }
  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = { }
  override def onEnvironmentUpdate(environmentUpdate: SparkListenerEnvironmentUpdate): Unit = { }
  override def onBlockManagerAdded(blockManagerAdded: SparkListenerBlockManagerAdded): Unit = { }
  override def onBlockManagerRemoved(
      blockManagerRemoved: SparkListenerBlockManagerRemoved): Unit = { }
  override def onUnpersistRDD(unpersistRDD: SparkListenerUnpersistRDD): Unit = { }
  override def onApplicationStart(applicationStart: SparkListenerApplicationStart): Unit = { }
  override def onApplicationEnd(applicationEnd: SparkListenerApplicationEnd): Unit = { }
  override def onExecutorMetricsUpdate(
      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = { }
  override def onExecutorAdded(executorAdded: SparkListenerExecutorAdded): Unit = { }
  override def onExecutorRemoved(executorRemoved: SparkListenerExecutorRemoved): Unit = { }
  override def onBlockUpdated(blockUpdated: SparkListenerBlockUpdated): Unit = { }
  override def onOtherEvent(event: SparkListenerEvent): Unit = { }
}
</code></pre>

<p>Spark运行过程中会用到很多个SparkListener，每一种都有自己的用途。</p>

<p>例如EventLoggingListener用来将监听到的事件持久化到文件中，ExecutorAllocationListener用那个通知对应的ExecutorAllocationManager增加或移除executor等。</p>

<h2>SparkListenerBus</h2>

<p>SparkListener需要被注册到SparkListenerBus中才能起作用，SparkListenerBus负责分发监听到的Event给SparkListener。</p>

<p>SparkListenerBus继承自ListenerBus接口，并重载了doPostEvent方法。</p>

<pre><code class="scala">private[spark] trait SparkListenerBus
  extends ListenerBus[SparkListenerInterface, SparkListenerEvent] {

  protected override def doPostEvent(
      listener: SparkListenerInterface,
      event: SparkListenerEvent): Unit = {
    event match {
      case stageSubmitted: SparkListenerStageSubmitted =&gt;
        listener.onStageSubmitted(stageSubmitted)
      case stageCompleted: SparkListenerStageCompleted =&gt;
        listener.onStageCompleted(stageCompleted)
      case jobStart: SparkListenerJobStart =&gt;
        listener.onJobStart(jobStart)
      case jobEnd: SparkListenerJobEnd =&gt;
        listener.onJobEnd(jobEnd)
      ...
      case blockUpdated: SparkListenerBlockUpdated =&gt;
        listener.onBlockUpdated(blockUpdated)
      case logStart: SparkListenerLogStart =&gt; // ignore event log metadata
      case _ =&gt; listener.onOtherEvent(event)
    }
  }

}
</code></pre>

<p>该接口实现了消息的路由，根据事件类型调用相应的处理函数。</p>

<h3>ListenerBus</h3>

<p>ListenerBus接口的实现如下：</p>

<pre><code>private[spark] trait ListenerBus[L &lt;: AnyRef, E] extends Logging {

  // Marked `private[spark]` for access in tests.
  private[spark] val listeners = new CopyOnWriteArrayList[L]

  final def addListener(listener: L): Unit = {
    listeners.add(listener)
  }

  final def removeListener(listener: L): Unit = {
    listeners.remove(listener)
  }

  /**
   * Post the event to all registered listeners. The `postToAll` caller should guarantee calling
   * `postToAll` in the same thread for all events.
   */
  final def postToAll(event: E): Unit = {
    // JavaConverters can create a JIterableWrapper if we use asScala.
    // However, this method will be called frequently. To avoid the wrapper cost, here we use
    // Java Iterator directly.
    val iter = listeners.iterator
    while (iter.hasNext) {
      val listener = iter.next()
      try {
        doPostEvent(listener, event)
      } catch {
        case NonFatal(e) =&gt;
          logError(s"Listener ${Utils.getFormattedClassName(listener)} threw an exception", e)
      }
    }
  }

  /**
   * Post an event to the specified listener. `onPostEvent` is guaranteed to be called in the same
   * thread for all listeners.
   */
  protected def doPostEvent(listener: L, event: E): Unit

  private[spark] def findListenersByClass[T &lt;: L : ClassTag](): Seq[T] = {
    val c = implicitly[ClassTag[T]].runtimeClass
    listeners.asScala.filter(_.getClass == c).map(_.asInstanceOf[T]).toSeq
  }

}
</code></pre>

<p>本质上所有注册的Listener用一个数组记录下来，post操作就是根据事件找到对应的listener然后把event交给listener处理。</p>

<h3>LiveListenerBus</h3>

<p>SparkContext中会创建一个LiveListenerBus实例，LiveListenerBus是SparkListenerBus的一个具体实现，主要功能如下:</p>

<ul>
<li>保存有消息队列,负责消息的缓存</li>
<li>保存有注册过的listener,负责消息的分发</li>
</ul>


<p>消息队列用LinkBlockQueue实现：</p>

<pre><code class="scala">// Cap the capacity of the event queue so we get an explicit error (rather than
// an OOM exception) if it's perpetually being added to more quickly than it's being drained.
private lazy val EVENT_QUEUE_CAPACITY = validateAndGetQueueSize()
private lazy val eventQueue = new LinkedBlockingQueue[SparkListenerEvent](EVENT_QUEUE_CAPACITY)
</code></pre>

<p>事件队列的长度EVENT_QUEUE_CAPACITY由spark.scheduler.listenerbus.eventqueue.size参数配置，默认为10000。</p>

<p>当缓存事件数量达到上限后,新来的事件会被丢弃。</p>

<p>消息的产生和分发按照 <b><font color=red>生产者-消费者模型</font></b> 实现。</p>

<p><b><font color=red>消息的分发(消费者)</font></b> 是通过一个listener线程异步处理的，代码如下。</p>

<pre><code class="scala">private val listenerThread = new Thread(name) {  // &lt;-- 线程名为SparkListenerBus
  setDaemon(true)
  override def run(): Unit = Utils.tryOrStopSparkContext(sparkContext) {
    LiveListenerBus.withinListenerThread.withValue(true) {
      while (true) {
        eventLock.acquire()
        self.synchronized {
          processingEvent = true
        }
        try {
          val event = eventQueue.poll
          if (event == null) {
            // Get out of the while loop and shutdown the daemon thread
            if (!stopped.get) {
              throw new IllegalStateException("Polling `null` from eventQueue means" +
                " the listener bus has been stopped. So `stopped` must be true")
            }
            return
          }
          postToAll(event)
        } finally {
          self.synchronized {
            processingEvent = false
          }
        }
      }
    }
  }
}
</code></pre>

<p>为了保证生产者和消费者对消息队列的并发访问，在每次需要获取消息的时候,调用eventLock.acquire()来获取信号量, 信号量的值就是当前队列中所含有的事件数量。</p>

<p>如果正常获取到事件,就调用postToAll将事件分发给所有listener, 继续下一次循环。</p>

<p>如果获取到null值, 则有下面两种情况:</p>

<ul>
<li>整个application正常结束, 此时stopped值已经被设置为true。</li>
<li>系统发生了错误, 立即终止运行。</li>
</ul>


<p><font color=red><b>消息的产生(生产者)</font></b> 通过在Spark运行时调用LiveListenerBus的post方法来添加。实现如下：</p>

<pre><code class="scala">def post(event: SparkListenerEvent): Unit = {
  if (stopped.get) {
    // Drop further events to make `listenerThread` exit ASAP
    logError(s"$name has already stopped! Dropping event $event")
    return
  }
  val eventAdded = eventQueue.offer(event)  // &lt;-- 这里将新来的事件添加到消息队列中
  if (eventAdded) {
    eventLock.release()
  } else {
    onDropEvent(event)  // &lt;-- 没有添加成功，则丢弃事件
    droppedEventsCounter.incrementAndGet()
  }

  val droppedEvents = droppedEventsCounter.get
  if (droppedEvents &gt; 0) {
    // Don't log too frequently
    if (System.currentTimeMillis() - lastReportTimestamp &gt;= 60 * 1000) {
      // There may be multiple threads trying to decrease droppedEventsCounter.
      // Use "compareAndSet" to make sure only one thread can win.
      // And if another thread is increasing droppedEventsCounter, "compareAndSet" will fail and
      // then that thread will update it.
      if (droppedEventsCounter.compareAndSet(droppedEvents, 0)) {
        val prevLastReportTimestamp = lastReportTimestamp
        lastReportTimestamp = System.currentTimeMillis()
        logWarning(s"Dropped $droppedEvents SparkListenerEvents since " +
          new java.util.Date(prevLastReportTimestamp))
      }
    }
  }
}
</code></pre>

<p>每成功放入一个事件,就调用eventLock.release()来增加信号量额值，以供消费者线程来进行消费. 如果队列满了,就调用onDropEvent来处理。</p>

<h2>消息队列建立/发送流程</h2>

<p>在SparkContext中创建了LiveListenerBus类类型的成员变量listenerBus。</p>

<pre><code class="scala">// An asynchronous listener bus for Spark events
private[spark] val listenerBus = new LiveListenerBus(this)
随后创建各种listener，并注册到listenerBus中，通过调用listenerBus的start()方法启动消息分发流程。
private def setupAndStartListenerBus(): Unit = {
  // Use reflection to instantiate listeners specified via `spark.extraListeners`
  try {
    val listenerClassNames: Seq[String] =
      conf.get("spark.extraListeners", "").split(',').map(_.trim).filter(_ != "")  
    for (className &lt;- listenerClassNames) {  // &lt;-- 如果指定了额外的SparkListenr类，可通过反射机制实例化并注册到listenerBus
      // Use reflection to find the right constructor
      val constructors = {
        val listenerClass = Utils.classForName(className)
        listenerClass
            .getConstructors
            .asInstanceOf[Array[Constructor[_ &lt;: SparkListenerInterface]]]
      }
      val constructorTakingSparkConf = constructors.find { c =&gt;
        c.getParameterTypes.sameElements(Array(classOf[SparkConf]))
      }
      lazy val zeroArgumentConstructor = constructors.find { c =&gt;
        c.getParameterTypes.isEmpty
      }
      val listener: SparkListenerInterface = {
        if (constructorTakingSparkConf.isDefined) {
          constructorTakingSparkConf.get.newInstance(conf)
        } else if (zeroArgumentConstructor.isDefined) {
          zeroArgumentConstructor.get.newInstance()
        } else {
          ...
        }
      }
      listenerBus.addListener(listener)
      logInfo(s"Registered listener $className")
    }
  } catch {
    ...
  }

  listenerBus.start()
  _listenerBusStarted = true
}
</code></pre>

<p>其中，listenerBus.start() 实现如下：</p>

<pre><code class="scala">def start(): Unit = {
  if (started.compareAndSet(false, true)) {
    listenerThread.start()
  } else {
    throw new IllegalStateException(s"$name already started!")
  }
}
</code></pre>

<p>运行过程中产生的事件会post到listenerBus中。</p>

<p>当作业运行结束后会调用listenerBus.stop()来停止SparkListenerBus线程。</p>

<pre><code class="scala">def stop(): Unit = {
  if (!started.get()) {
    throw new IllegalStateException(s"Attempted to stop $name that has not yet started!")
  }
  if (stopped.compareAndSet(false, true)) {
    // Call eventLock.release() so that listenerThread will poll `null` from `eventQueue` and know
    // `stop` is called.
    eventLock.release()
    listenerThread.join()
  } else {
    // Keep quiet
  }
}
</code></pre>

<p>这里可以看到：</p>

<p><b><font color=red>在stop函数中调用了eventLock.release()来增加信号量的值. 然而并未向消息队列中加入新的消息。</p>

<p>这就导致在消费者线程listenerThread读取队列时会返回null值,进而达到结束listenerThread线程的目的。</font></b></p>

<p>以上就是Spark Core中消息队列机制的整体工作流程。</p>

<p><b>参考资料</b></p>

<ol>
<li>Spark 2.0 源码：<a href="https://github.com/apache/spark/tree/branch-2.0">https://github.com/apache/spark/tree/branch-2.0</a></li>
<li>Spark消息队列机制源码学习Blog：<a href="http://blog.csdn.net/sivolin/article/details/47316099">http://blog.csdn.net/sivolin/article/details/47316099</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark日志配置方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa/"/>
    <updated>2016-10-19T19:13:38+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa</id>
    <content type="html"><![CDATA[<p>本文介绍Spark日志级别控制方法。</p>

<p>Apache Spark 默认使用 log4j 作为日志工具。
Baidu Spark 根据不同的发布版本，使用 log4j 或者 logback 作为日志工具。</p>

<!--more-->


<h2>Driver日志级别设置</h2>

<p>日志配置默认在Spark客户端conf目录下，log4j配置log4j.properties文件，logback配置logback.xml文件。</p>

<h3>log4j配置示例</h3>

<p>示例配置文件log4j.properties如下：</p>

<pre><code class="bash"># Set everything to be logged to the console
log4j.rootCategory=INFO, DRFA
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.File=log/spark.log
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DRFA.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} [%t] %p %c{1}: %m%n
# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.hadoop.fs.DfsInputStream=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.*=DEBUG
</code></pre>

<p>其中：</p>

<ul>
<li>log4j.rootCategory配置总体的默认日志级别。</li>
<li>log4j.appender.DRFA.File用来配置日志重定向的目标文件。</li>
<li>log4j.appender.DRFA.layout.ConversionPattern用来配置日志的输出格式。</li>
<li>log4j.logger.xxx.xxx.xxx用来配置指定类的日志级别，xxx.xxx.xxx代表类路径。</li>
</ul>


<h3>logback配置示例</h3>

<p>示例配置文件logback.xml如下：</p>

<pre><code class="xml">&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;appender name="RFILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
    &lt;file&gt;log/spark.log&lt;/file&gt;
    &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
      &lt;fileNamePattern&gt;log/spark.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;
      &lt;maxHistory&gt;30&lt;/maxHistory&gt;
    &lt;/rollingPolicy&gt;
    &lt;encoder&gt;
      &lt;pattern&gt; %date %level [%logger] - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt;
  &lt;logger name="org.apache.hadoop.hive.ql.io.*"  level="INFO" /&gt;
  &lt;root level="info"&gt;
    &lt;appender-ref ref="RFILE" /&gt;
  &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>

<p>其中：</p>

<ul>
<li><root>用来配置总体的默认日志级别。</li>
<li><file>用来配置日志重定向的目标文件。</li>
<li><pattern>用来配置日志的输出格式。</li>
<li><logger>用来配置指定类的日志级别。</li>
</ul>


<h2>Executor日志级别设置</h2>

<p>executor日志级别配置同driver端类似，但需要将executor的日志配置文件上传，并通过executor的Java参数指定使用的配置文件名。</p>

<h3>log4j配置示例</h3>

<p>配置好executor的log4j配置文件，命名随意，假设为executor-log4j.properties，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlog4j.configuration=executor-log4j.properties
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-log4j.properties xxx
则作业运行时的日志级别将由executor-log4j.properties文件控制。
</code></pre>

<h3>logback配置示例</h3>

<p>配置好executor的logback配置文件，命名随意，假设为executor-logback.xml，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlogback.configurationFile=executor-logback.xml
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-logback.xml xxx
</code></pre>

<p>则作业运行时的日志级别将由executor-logback.xml文件控制。</p>
]]></content>
  </entry>
  
</feed>
