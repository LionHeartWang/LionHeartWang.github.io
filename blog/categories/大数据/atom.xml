<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大数据 | Workspace of LionHeart]]></title>
  <link href="http://lionheartwang.github.io/blog/categories/大数据/atom.xml" rel="self"/>
  <link href="http://lionheartwang.github.io/"/>
  <updated>2016-10-19T19:21:12+08:00</updated>
  <id>http://lionheartwang.github.io/</id>
  <author>
    <name><![CDATA[Wang Yiguang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Spark日志配置方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa/"/>
    <updated>2016-10-19T19:13:38+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa</id>
    <content type="html"><![CDATA[<p>本文介绍Spark日志级别控制方法。</p>

<p>Apache Spark 默认使用 log4j 作为日志工具。
Baidu Spark 根据不同的发布版本，使用 log4j 或者 logback 作为日志工具。</p>

<!--more-->


<h2>Driver日志级别设置</h2>

<p>日志配置默认在Spark客户端conf目录下，log4j配置log4j.properties文件，logback配置logback.xml文件。</p>

<h3>log4j配置示例</h3>

<p>示例配置文件log4j.properties如下：</p>

<pre><code class="bash"># Set everything to be logged to the console
log4j.rootCategory=INFO, DRFA
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.File=log/spark.log
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DRFA.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} [%t] %p %c{1}: %m%n
# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.hadoop.fs.DfsInputStream=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.*=DEBUG
</code></pre>

<p>其中：</p>

<ul>
<li>log4j.rootCategory配置总体的默认日志级别。</li>
<li>log4j.appender.DRFA.File用来配置日志重定向的目标文件。</li>
<li>log4j.appender.DRFA.layout.ConversionPattern用来配置日志的输出格式。</li>
<li>log4j.logger.xxx.xxx.xxx用来配置指定类的日志级别，xxx.xxx.xxx代表类路径。</li>
</ul>


<h3>logback配置示例</h3>

<p>示例配置文件logback.xml如下：</p>

<pre><code class="xml">&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;appender name="RFILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
    &lt;file&gt;log/spark.log&lt;/file&gt;
    &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
      &lt;fileNamePattern&gt;log/spark.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;
      &lt;maxHistory&gt;30&lt;/maxHistory&gt;
    &lt;/rollingPolicy&gt;
    &lt;encoder&gt;
      &lt;pattern&gt; %date %level [%logger] - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt;
  &lt;logger name="org.apache.hadoop.hive.ql.io.*"  level="INFO" /&gt;
  &lt;root level="info"&gt;
    &lt;appender-ref ref="RFILE" /&gt;
  &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>

<p>其中：</p>

<ul>
<li><root>用来配置总体的默认日志级别。</li>
<li><file>用来配置日志重定向的目标文件。</li>
<li><pattern>用来配置日志的输出格式。</li>
<li><logger>用来配置指定类的日志级别。</li>
</ul>


<h2>Executor日志级别设置</h2>

<p>executor日志级别配置同driver端类似，但需要将executor的日志配置文件上传，并通过executor的Java参数指定使用的配置文件名。</p>

<h3>log4j配置示例</h3>

<p>配置好executor的log4j配置文件，命名随意，假设为executor-log4j.properties，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlog4j.configuration=executor-log4j.properties
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-log4j.properties xxx
则作业运行时的日志级别将由executor-log4j.properties文件控制。
</code></pre>

<h3>logback配置示例</h3>

<p>配置好executor的logback配置文件，命名随意，假设为executor-logback.xml，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlogback.configurationFile=executor-logback.xml
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-logback.xml xxx
</code></pre>

<p>则作业运行时的日志级别将由executor-logback.xml文件控制。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark HistoryServer 配置和使用方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/08/24/spark-historyserver-configuration/"/>
    <updated>2016-08-24T17:17:58+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/08/24/spark-historyserver-configuration</id>
    <content type="html"><![CDATA[<p>本文介绍Spark History Server的配置和使用方法。</p>

<!--More-->


<h2>History Server 配置</h2>

<p>Spark提供了History Server服务可以保存历史Application的运行记录。</p>

<h3>客户端配置</h3>

<p>对于提交应用程序的客户端需要在conf/spark-defaults.conf中配置以下参数：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.eventLog.enabled      </td>
<td style="text-align:left;"> 是否记录Spark事件，用于应用程序在完成后重构webUI。 </td>
</tr>
<tr>
<td> spark.eventLog.dir      </td>
<td style="text-align:left;"> spark.eventLog.enabled为 true，该属性为记录spark事件的根目录。在此根目录中，Spark为每个应用程序创建分目录，并将应用程序的事件记录到此目录中。<br>可以将此属性设置为HDFS目录，以便history server读取历史记录文件。</br>      </td>
</tr>
<tr>
<td> spark.yarn.historyServer.address </td>
<td style="text-align:left;"> Spark history server的地址。 这个地址会在Spark应用程序完成后提交给YARN RM，然后RM将信息从RM UI写到history server UI上。<br><strong><font color=red>注意：hostname:port，前面不加http：//，末尾也不要加反斜杠。</font></strong> </br>     </td>
</tr>
</tbody>
</table>


<h3>服务端配置</h3>

<p>服务端主要需要在conf/spark-defaults.conf中配置如下属性：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
<th style="text-align:left;"> 默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.history.ui.port     </td>
<td style="text-align:left;"> History Server的默认访问端口。<strong><font color=red>建议配置在8000~9000之间，以确保再内网浏览器能够正常显示。</strong><font color=red> </td>
<td style="text-align:left;"> 18080 </td>
</tr>
<tr>
<td> spark.history.fs.logDirectory    </td>
<td style="text-align:left;">   用于指定HistoryServer读取的eventlog存放的hdfs路径。  </td>
<td style="text-align:left;">无</td>
</tr>
<tr>
<td> spark.history.updateInterval </td>
<td style="text-align:left;">  History Server显示信息的刷新时间间隔，以秒为单位。每次更新都会检查持久层事件日志的任何变化。  </td>
<td style="text-align:left;"> 10 </td>
</tr>
<tr>
<td>spark.history.retainedApplications</td>
<td style="text-align:left;">在History Server上显示的最大应用程序数量，如果超过这个值，旧的应用程序信息将被删除。</td>
<td style="text-align:left;">250</td>
</tr>
</tbody>
</table>


<p>如果使用Kerberos认证可以配置如下参数：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
<th style="text-align:left;"> 默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.history.kerberos.enabled    </td>
<td style="text-align:left;"> 是否使用kerberos方式登录访问history server。</td>
<td style="text-align:left;">false</td>
</tr>
<tr>
<td>spark.history.kerberos.principal</td>
<td style="text-align:left;">spark.history.kerberos.enabled为true时使用，用于指定History Server的kerberos主体名称</td>
<td style="text-align:left;">空</td>
</tr>
<tr>
<td>spark.history.kerberos.keytab</td>
<td style="text-align:left;">spark.history.kerberos.enabled为true时使用，用于指定History Server的kerberos keytab文件位置</td>
<td style="text-align:left;">空</td>
</tr>
<tr>
<td>spark.history.ui.acls.enable</td>
<td style="text-align:left;">授权用户查看应用程序信息的时候是否检查acl。如果启用，无论应用程序的spark.ui.acls.enable怎么设置，都要进行授权检查。<br>只有应用程序所有者和spark.ui.view.acls指定的用户可以查看应用程序信息; 如果禁用，不做任何检查。</br></td>
<td style="text-align:left;">false</td>
</tr>
</tbody>
</table>


<p>另外，服务端可以配置以下环境变量：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
</tr>
</thead>
<tbody>
<tr>
<td>SPARK_DAEMON_JAVA_OPTS</td>
<td style="text-align:left;">History Server的JVM参数，默认为空</td>
</tr>
<tr>
<td>SPARK_DAEMON_MEMORY</td>
<td style="text-align:left;">分配给History Server的内存大小，默认512M</td>
</tr>
<tr>
<td>SPARK_HISTORY_OPTS</td>
<td style="text-align:left;">History Server的属性设置，默认为空。</td>
</tr>
<tr>
<td>SPARK_PUBLIC_DNS</td>
<td style="text-align:left;">History Server的公网地址，如果不设置，可以用内网地址来访问，默认为空。</td>
</tr>
</tbody>
</table>


<h2>History Server 使用</h2>

<h3>启动</h3>

<p>一般将客户端运行生成的eventlog统一存放在一个HDFS路径下便于查询历史记录，然后History Server端 spark.history.fs.logDirectory的值设为该路径即可。</p>

<p>启动History Server命令：</p>

<pre><code>$sh sbin/start-history-server.sh
</code></pre>

<h3>停止</h3>

<p>停止History Server命令：</p>

<pre><code>$sh sbin/stop-history-server.sh
</code></pre>
]]></content>
  </entry>
  
</feed>
