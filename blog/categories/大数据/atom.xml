<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[大数据 | Workspace of LionHeart]]></title>
  <link href="http://lionheartwang.github.io/blog/categories/大数据/atom.xml" rel="self"/>
  <link href="http://lionheartwang.github.io/"/>
  <updated>2017-04-17T19:02:56+08:00</updated>
  <id>http://lionheartwang.github.io/</id>
  <author>
    <name><![CDATA[Wang Yiguang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ZooKeeper安装使用指南]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/01/20/zookeeperan-zhuang-shi-yong-zhi-nan/"/>
    <updated>2017-01-20T15:56:22+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/01/20/zookeeperan-zhuang-shi-yong-zhi-nan</id>
    <content type="html"><![CDATA[<p>ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务。</p>

<p>作为分布式应用提供一致性服务的软件，ZooKeeper 封装了易错的关键服务，提供简单高效、功能稳定接口给用户</p>

<p>本文介绍 ZooKeeper 的配置方法和客户端使用方法。</p>

<!--more-->


<h2>ZooKeeper 安装</h2>

<p>以ZooKeeper 3.4.8为例，下载 <a href="http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.8/">ZooKeeper 3.4.8</a>
下载解压后配置conf/zoo.cfg，配置clientPort，dataDir等。
示例配置：</p>

<pre><code class="bash"># The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial synchronization phase can take
initLimit=10
# The number of ticks that can pass between sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored. do not use /tmp for storage, /tmp here is just example sakes.
dataDir=/tmp/zookeeper
# the port at which the clients will connect
clientPort=2181
</code></pre>

<h2>ZooKeeper 使用</h2>

<p>配置好Zk后需要先启动ZkServer，然后可以用Zk Client直接以命令行的方式操作Zk。</p>

<h3>Server端</h3>

<p>配置好后启动zk：</p>

<pre><code class="bash">$sh bin/zkServer.sh start &gt; zookeeper.out
</code></pre>

<h3>Client端</h3>

<p>ZooKeeper客户端的使用非常简单，启动：</p>

<pre><code class="bash"># ip和端口根据启动情况修改
$sh bin/zkCli.sh -server 127.0.0.1:2181
</code></pre>

<p>之后可以用ls、delete、get等命令查询或修改各ZK节点的值。命令帮助如下：</p>

<pre><code>ZooKeeper -server host:port cmd args
    connect host:port
    get path [watch]
    ls path [watch]
    set path data [version]
    rmr path
    delquota [-n|-b] path
    quit
    printwatches on|off
    create [-s] [-e] path data acl
    stat path [watch]
    close
    ls2 path [watch]
    history
    listquota path
    setAcl path acl
    getAcl path
    sync path
    redo cmdno
    addauth scheme auth
    delete path [version]
    setquota -n|-b val path
</code></pre>

<h2>ZooKeeper API</h2>

<p>除了通过客户端操作ZooKeeper，还可以调用ZooKeeper提供的API操作ZooKeeper的节点。</p>

<p>这里以ZooKeeper 3.4.5为例，介绍常用的几个Java API。</p>

<h3>建立连接</h3>

<p>在应用程序中使用Zk需要先创建ZooKeeper对象，后续的操作都是基于该对象进行的。</p>

<pre><code class="java">public ZooKeeper(String connectString, int sessionTimeout, Watcher watcher) throws IOException  
</code></pre>

<p>参数说明：</p>

<ul>
<li>connectString： zookeeper server列表, 以逗号隔开。ZooKeeper对象初始化后, 将从列表中选择一个server, 并尝试建立连接。如果失败,则会从剩余项中选择并再次尝试建立连接。</li>
<li>sessionTimeout：指定连接的超时时间.</li>
<li>watcher： 事件回调接口。</li>
</ul>


<h3>创建/删除znode</h3>

<p>ZooKeeper对象的create/delete方法用于创建/删除 znode。如果该node存在, 则返回该node的状态信息, 否则返回null。</p>

<pre><code class="java">public String create(String path, byte[] data, List acl, CreateMode createMode); 
public void delete(final String path, int version);  
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>data：与znode关联的数据。</li>
<li>acl：指定权限信息</li>
<li>createMode：指定znode类型，按持久化节点与临时节点，以及自动编号节点与非自动编号节点两个维度划分，共4类。</li>
<li>version：指定要更新的数据的版本, 如果version和真实的版本不同, 更新操作将失败.。指定version为-1则忽略版本检查。</li>
</ul>


<h3>获取子znode列表</h3>

<p>ZooKeeper对象的getChildren方法用于获取子node列表。</p>

<pre><code class="java">public List getChildren(String path, boolean watch); 
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>watch参数用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
</ul>


<h3>判断znode是否存在</h3>

<p>ZooKeeper对象的exists方法用于判断指定znode是否存在。如果该node存在, 则返回该node的状态信息, 否则返回null。</p>

<pre><code class="java">public Stat exists(String path, boolean watch);  
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>watch：用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
</ul>


<h3>获取/更新znode数据</h3>

<p>ZooKeeper对象的getData/setData方法用于获取/更新 znode关联的数据。</p>

<pre><code class="java">public byte[] getData(String path, boolean watch, Stat stat);  
public Stat setData(final String path, byte data[], int version); 
</code></pre>

<p>参数说明：</p>

<ul>
<li>path： znode的路径。</li>
<li>stat：传出参数, getData方法会将path node的状态信息设置到该参数中。</li>
<li>data：与znode关联的数据。</li>
<li>watch：用于指定是否监听path node的创建, 删除事件, 以及数据更新事件。</li>
<li>version：指定要更新的数据的版本, 如果version和真实的版本不同, 更新操作将失败.。指定version为-1则忽略版本检查。</li>
</ul>


<p>更全的API介绍参考 ZooKeeper 3.4.5 API</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark Core 消息队列机制]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/11/28/spark-core-message-queue-mechanism/"/>
    <updated>2016-11-28T14:31:03+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/11/28/spark-core-message-queue-mechanism</id>
    <content type="html"><![CDATA[<p>本文介绍Spark中的消息队列机制，首先SparkListenerEvent，SparkListener和SparkListenerBus等基本数据结构实现。</p>

<p>重点介绍了异步消息总线LiveListenerBus的实现。随后介绍了Spark消息队列的整体工作流程。</p>

<!--more-->


<h2>SparkListenerEvent</h2>

<p>Spark中的消息由SparkListenerEvent表示。其本身定义只是一个接口：</p>

<pre><code class="scala">trait SparkListenerEvent {
  /* Whether output this event to the event log */
  protected[spark] def logEvent: Boolean = true
}
</code></pre>

<p>SparkListenerEvent有多个具体的实现，每种实现代表了Spark运行过程中的一种事件。</p>

<ul>
<li>SparkListenerStageSubmitted</li>
<li>SparkListenerStageCompleted</li>
<li>SparkListenerTaskStart</li>
<li>SparkListenerTaskGettingResult</li>
<li>SparkListenerTaskEnd</li>
<li>SparkListenerJobStart</li>
<li>SparkListenerJobEnd</li>
<li>SparkListenerEnvironmentUpdate</li>
<li>SparkListenerBlockManagerAdded</li>
<li>SparkListenerBlockManagerRemoved</li>
<li>SparkListenerUnpersistRDD</li>
<li>SparkListenerExecutorAdded</li>
<li>SparkListenerExecutorRemoved</li>
<li>SparkListenerBlockUpdated</li>
<li>SparkListenerExecutorMetricsUpdate</li>
<li>SparkListenerApplicationStart</li>
<li>SparkListenerApplicationEnd</li>
<li>SparkListenerLogStart</li>
</ul>


<p>根据名称可以知道每一种事件代表的含义。</p>

<h2>SparkListener</h2>

<p>SparkListeners负责监听SparkListenerEvents。</p>

<p>所有Spark消息SparkListenerEvents 被异步的发送给已经注册过的SparkListeners。</p>

<p>SparkListenerInterface定义了SparkListener的接口：</p>

<ul>
<li>onStageCompleted</li>
<li>onStageSubmitted</li>
<li>onTaskStart</li>
<li>onTaskGettingResult</li>
<li>onTaskEnd</li>
<li>onJobStart</li>
<li>onJobEnd</li>
<li>onEnvironmentUpdate</li>
<li>onBlockManagerAdded</li>
<li>onBlockManagerRemoved</li>
<li>onUnpersistRDD</li>
<li>onApplicationStart</li>
<li>onApplicationEnd</li>
<li>onExecutorMetricsUpdate</li>
<li>onExecutorAdded</li>
<li>onExecutorRemoved</li>
<li>onBlockUpdated</li>
<li>onOtherEvent</li>
</ul>


<p>根据名称可以知道每一个方法是对应事件消息的响应函数。SparkListener的实现：</p>

<pre><code class="scala">abstract class SparkListener extends SparkListenerInterface {
  override def onStageCompleted(stageCompleted: SparkListenerStageCompleted): Unit = { }
  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = { }
  override def onTaskStart(taskStart: SparkListenerTaskStart): Unit = { }
  override def onTaskGettingResult(taskGettingResult: SparkListenerTaskGettingResult): Unit = { }
  override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = { }
  override def onJobStart(jobStart: SparkListenerJobStart): Unit = { }
  override def onJobEnd(jobEnd: SparkListenerJobEnd): Unit = { }
  override def onEnvironmentUpdate(environmentUpdate: SparkListenerEnvironmentUpdate): Unit = { }
  override def onBlockManagerAdded(blockManagerAdded: SparkListenerBlockManagerAdded): Unit = { }
  override def onBlockManagerRemoved(
      blockManagerRemoved: SparkListenerBlockManagerRemoved): Unit = { }
  override def onUnpersistRDD(unpersistRDD: SparkListenerUnpersistRDD): Unit = { }
  override def onApplicationStart(applicationStart: SparkListenerApplicationStart): Unit = { }
  override def onApplicationEnd(applicationEnd: SparkListenerApplicationEnd): Unit = { }
  override def onExecutorMetricsUpdate(
      executorMetricsUpdate: SparkListenerExecutorMetricsUpdate): Unit = { }
  override def onExecutorAdded(executorAdded: SparkListenerExecutorAdded): Unit = { }
  override def onExecutorRemoved(executorRemoved: SparkListenerExecutorRemoved): Unit = { }
  override def onBlockUpdated(blockUpdated: SparkListenerBlockUpdated): Unit = { }
  override def onOtherEvent(event: SparkListenerEvent): Unit = { }
}
</code></pre>

<p>Spark运行过程中会用到很多个SparkListener，每一种都有自己的用途。</p>

<p>例如EventLoggingListener用来将监听到的事件持久化到文件中，ExecutorAllocationListener用那个通知对应的ExecutorAllocationManager增加或移除executor等。</p>

<h2>SparkListenerBus</h2>

<p>SparkListener需要被注册到SparkListenerBus中才能起作用，SparkListenerBus负责分发监听到的Event给SparkListener。</p>

<p>SparkListenerBus继承自ListenerBus接口，并重载了doPostEvent方法。</p>

<pre><code class="scala">private[spark] trait SparkListenerBus
  extends ListenerBus[SparkListenerInterface, SparkListenerEvent] {

  protected override def doPostEvent(
      listener: SparkListenerInterface,
      event: SparkListenerEvent): Unit = {
    event match {
      case stageSubmitted: SparkListenerStageSubmitted =&gt;
        listener.onStageSubmitted(stageSubmitted)
      case stageCompleted: SparkListenerStageCompleted =&gt;
        listener.onStageCompleted(stageCompleted)
      case jobStart: SparkListenerJobStart =&gt;
        listener.onJobStart(jobStart)
      case jobEnd: SparkListenerJobEnd =&gt;
        listener.onJobEnd(jobEnd)
      ...
      case blockUpdated: SparkListenerBlockUpdated =&gt;
        listener.onBlockUpdated(blockUpdated)
      case logStart: SparkListenerLogStart =&gt; // ignore event log metadata
      case _ =&gt; listener.onOtherEvent(event)
    }
  }

}
</code></pre>

<p>该接口实现了消息的路由，根据事件类型调用相应的处理函数。</p>

<h3>ListenerBus</h3>

<p>ListenerBus接口的实现如下：</p>

<pre><code>private[spark] trait ListenerBus[L &lt;: AnyRef, E] extends Logging {

  // Marked `private[spark]` for access in tests.
  private[spark] val listeners = new CopyOnWriteArrayList[L]

  final def addListener(listener: L): Unit = {
    listeners.add(listener)
  }

  final def removeListener(listener: L): Unit = {
    listeners.remove(listener)
  }

  /**
   * Post the event to all registered listeners. The `postToAll` caller should guarantee calling
   * `postToAll` in the same thread for all events.
   */
  final def postToAll(event: E): Unit = {
    // JavaConverters can create a JIterableWrapper if we use asScala.
    // However, this method will be called frequently. To avoid the wrapper cost, here we use
    // Java Iterator directly.
    val iter = listeners.iterator
    while (iter.hasNext) {
      val listener = iter.next()
      try {
        doPostEvent(listener, event)
      } catch {
        case NonFatal(e) =&gt;
          logError(s"Listener ${Utils.getFormattedClassName(listener)} threw an exception", e)
      }
    }
  }

  /**
   * Post an event to the specified listener. `onPostEvent` is guaranteed to be called in the same
   * thread for all listeners.
   */
  protected def doPostEvent(listener: L, event: E): Unit

  private[spark] def findListenersByClass[T &lt;: L : ClassTag](): Seq[T] = {
    val c = implicitly[ClassTag[T]].runtimeClass
    listeners.asScala.filter(_.getClass == c).map(_.asInstanceOf[T]).toSeq
  }

}
</code></pre>

<p>本质上所有注册的Listener用一个数组记录下来，post操作就是根据事件找到对应的listener然后把event交给listener处理。</p>

<h3>LiveListenerBus</h3>

<p>SparkContext中会创建一个LiveListenerBus实例，LiveListenerBus是SparkListenerBus的一个具体实现，主要功能如下:</p>

<ul>
<li>保存有消息队列,负责消息的缓存</li>
<li>保存有注册过的listener,负责消息的分发</li>
</ul>


<p>消息队列用LinkBlockQueue实现：</p>

<pre><code class="scala">// Cap the capacity of the event queue so we get an explicit error (rather than
// an OOM exception) if it's perpetually being added to more quickly than it's being drained.
private lazy val EVENT_QUEUE_CAPACITY = validateAndGetQueueSize()
private lazy val eventQueue = new LinkedBlockingQueue[SparkListenerEvent](EVENT_QUEUE_CAPACITY)
</code></pre>

<p>事件队列的长度EVENT_QUEUE_CAPACITY由spark.scheduler.listenerbus.eventqueue.size参数配置，默认为10000。</p>

<p>当缓存事件数量达到上限后,新来的事件会被丢弃。</p>

<p>消息的产生和分发按照 <b><font color=red>生产者-消费者模型</font></b> 实现。</p>

<p><b><font color=red>消息的分发(消费者)</font></b> 是通过一个listener线程异步处理的，代码如下。</p>

<pre><code class="scala">private val listenerThread = new Thread(name) {  // &lt;-- 线程名为SparkListenerBus
  setDaemon(true)
  override def run(): Unit = Utils.tryOrStopSparkContext(sparkContext) {
    LiveListenerBus.withinListenerThread.withValue(true) {
      while (true) {
        eventLock.acquire()
        self.synchronized {
          processingEvent = true
        }
        try {
          val event = eventQueue.poll
          if (event == null) {
            // Get out of the while loop and shutdown the daemon thread
            if (!stopped.get) {
              throw new IllegalStateException("Polling `null` from eventQueue means" +
                " the listener bus has been stopped. So `stopped` must be true")
            }
            return
          }
          postToAll(event)
        } finally {
          self.synchronized {
            processingEvent = false
          }
        }
      }
    }
  }
}
</code></pre>

<p>为了保证生产者和消费者对消息队列的并发访问，在每次需要获取消息的时候,调用eventLock.acquire()来获取信号量, 信号量的值就是当前队列中所含有的事件数量。</p>

<p>如果正常获取到事件,就调用postToAll将事件分发给所有listener, 继续下一次循环。</p>

<p>如果获取到null值, 则有下面两种情况:</p>

<ul>
<li>整个application正常结束, 此时stopped值已经被设置为true。</li>
<li>系统发生了错误, 立即终止运行。</li>
</ul>


<p><font color=red><b>消息的产生(生产者)</font></b> 通过在Spark运行时调用LiveListenerBus的post方法来添加。实现如下：</p>

<pre><code class="scala">def post(event: SparkListenerEvent): Unit = {
  if (stopped.get) {
    // Drop further events to make `listenerThread` exit ASAP
    logError(s"$name has already stopped! Dropping event $event")
    return
  }
  val eventAdded = eventQueue.offer(event)  // &lt;-- 这里将新来的事件添加到消息队列中
  if (eventAdded) {
    eventLock.release()
  } else {
    onDropEvent(event)  // &lt;-- 没有添加成功，则丢弃事件
    droppedEventsCounter.incrementAndGet()
  }

  val droppedEvents = droppedEventsCounter.get
  if (droppedEvents &gt; 0) {
    // Don't log too frequently
    if (System.currentTimeMillis() - lastReportTimestamp &gt;= 60 * 1000) {
      // There may be multiple threads trying to decrease droppedEventsCounter.
      // Use "compareAndSet" to make sure only one thread can win.
      // And if another thread is increasing droppedEventsCounter, "compareAndSet" will fail and
      // then that thread will update it.
      if (droppedEventsCounter.compareAndSet(droppedEvents, 0)) {
        val prevLastReportTimestamp = lastReportTimestamp
        lastReportTimestamp = System.currentTimeMillis()
        logWarning(s"Dropped $droppedEvents SparkListenerEvents since " +
          new java.util.Date(prevLastReportTimestamp))
      }
    }
  }
}
</code></pre>

<p>每成功放入一个事件,就调用eventLock.release()来增加信号量额值，以供消费者线程来进行消费. 如果队列满了,就调用onDropEvent来处理。</p>

<h2>消息队列建立/发送流程</h2>

<p>在SparkContext中创建了LiveListenerBus类类型的成员变量listenerBus。</p>

<pre><code class="scala">// An asynchronous listener bus for Spark events
private[spark] val listenerBus = new LiveListenerBus(this)
随后创建各种listener，并注册到listenerBus中，通过调用listenerBus的start()方法启动消息分发流程。
private def setupAndStartListenerBus(): Unit = {
  // Use reflection to instantiate listeners specified via `spark.extraListeners`
  try {
    val listenerClassNames: Seq[String] =
      conf.get("spark.extraListeners", "").split(',').map(_.trim).filter(_ != "")  
    for (className &lt;- listenerClassNames) {  // &lt;-- 如果指定了额外的SparkListenr类，可通过反射机制实例化并注册到listenerBus
      // Use reflection to find the right constructor
      val constructors = {
        val listenerClass = Utils.classForName(className)
        listenerClass
            .getConstructors
            .asInstanceOf[Array[Constructor[_ &lt;: SparkListenerInterface]]]
      }
      val constructorTakingSparkConf = constructors.find { c =&gt;
        c.getParameterTypes.sameElements(Array(classOf[SparkConf]))
      }
      lazy val zeroArgumentConstructor = constructors.find { c =&gt;
        c.getParameterTypes.isEmpty
      }
      val listener: SparkListenerInterface = {
        if (constructorTakingSparkConf.isDefined) {
          constructorTakingSparkConf.get.newInstance(conf)
        } else if (zeroArgumentConstructor.isDefined) {
          zeroArgumentConstructor.get.newInstance()
        } else {
          ...
        }
      }
      listenerBus.addListener(listener)
      logInfo(s"Registered listener $className")
    }
  } catch {
    ...
  }

  listenerBus.start()
  _listenerBusStarted = true
}
</code></pre>

<p>其中，listenerBus.start() 实现如下：</p>

<pre><code class="scala">def start(): Unit = {
  if (started.compareAndSet(false, true)) {
    listenerThread.start()
  } else {
    throw new IllegalStateException(s"$name already started!")
  }
}
</code></pre>

<p>运行过程中产生的事件会post到listenerBus中。</p>

<p>当作业运行结束后会调用listenerBus.stop()来停止SparkListenerBus线程。</p>

<pre><code class="scala">def stop(): Unit = {
  if (!started.get()) {
    throw new IllegalStateException(s"Attempted to stop $name that has not yet started!")
  }
  if (stopped.compareAndSet(false, true)) {
    // Call eventLock.release() so that listenerThread will poll `null` from `eventQueue` and know
    // `stop` is called.
    eventLock.release()
    listenerThread.join()
  } else {
    // Keep quiet
  }
}
</code></pre>

<p>这里可以看到：</p>

<p><b><font color=red>在stop函数中调用了eventLock.release()来增加信号量的值. 然而并未向消息队列中加入新的消息。</p>

<p>这就导致在消费者线程listenerThread读取队列时会返回null值,进而达到结束listenerThread线程的目的。</font></b></p>

<p>以上就是Spark Core中消息队列机制的整体工作流程。</p>

<p><b>参考资料</b></p>

<ol>
<li>Spark 2.0 源码：<a href="https://github.com/apache/spark/tree/branch-2.0">https://github.com/apache/spark/tree/branch-2.0</a></li>
<li>Spark消息队列机制源码学习Blog：<a href="http://blog.csdn.net/sivolin/article/details/47316099">http://blog.csdn.net/sivolin/article/details/47316099</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark日志配置方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa/"/>
    <updated>2016-10-19T19:13:38+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/10/19/sparkri-zhi-pei-zhi-fang-fa</id>
    <content type="html"><![CDATA[<p>本文介绍Spark日志级别控制方法。</p>

<p>Apache Spark 默认使用 log4j 作为日志工具。
Baidu Spark 根据不同的发布版本，使用 log4j 或者 logback 作为日志工具。</p>

<!--more-->


<h2>Driver日志级别设置</h2>

<p>日志配置默认在Spark客户端conf目录下，log4j配置log4j.properties文件，logback配置logback.xml文件。</p>

<h3>log4j配置示例</h3>

<p>示例配置文件log4j.properties如下：</p>

<pre><code class="bash"># Set everything to be logged to the console
log4j.rootCategory=INFO, DRFA
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.File=log/spark.log
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
log4j.appender.DRFA.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} [%t] %p %c{1}: %m%n
# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.hadoop.fs.DfsInputStream=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.orc.RecordReaderImpl=INFO
log4j.logger.org.apache.hadoop.hive.ql.io.*=DEBUG
</code></pre>

<p>其中：</p>

<ul>
<li>log4j.rootCategory配置总体的默认日志级别。</li>
<li>log4j.appender.DRFA.File用来配置日志重定向的目标文件。</li>
<li>log4j.appender.DRFA.layout.ConversionPattern用来配置日志的输出格式。</li>
<li>log4j.logger.xxx.xxx.xxx用来配置指定类的日志级别，xxx.xxx.xxx代表类路径。</li>
</ul>


<h3>logback配置示例</h3>

<p>示例配置文件logback.xml如下：</p>

<pre><code class="xml">&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;appender name="RFILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
    &lt;file&gt;log/spark.log&lt;/file&gt;
    &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
      &lt;fileNamePattern&gt;log/spark.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;
      &lt;maxHistory&gt;30&lt;/maxHistory&gt;
    &lt;/rollingPolicy&gt;
    &lt;encoder&gt;
      &lt;pattern&gt; %date %level [%logger] - %msg%n&lt;/pattern&gt;
    &lt;/encoder&gt;
  &lt;/appender&gt;
  &lt;logger name="org.apache.hadoop.hive.ql.io.*"  level="INFO" /&gt;
  &lt;root level="info"&gt;
    &lt;appender-ref ref="RFILE" /&gt;
  &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>

<p>其中：</p>

<ul>
<li><root>用来配置总体的默认日志级别。</li>
<li><file>用来配置日志重定向的目标文件。</li>
<li><pattern>用来配置日志的输出格式。</li>
<li><logger>用来配置指定类的日志级别。</li>
</ul>


<h2>Executor日志级别设置</h2>

<p>executor日志级别配置同driver端类似，但需要将executor的日志配置文件上传，并通过executor的Java参数指定使用的配置文件名。</p>

<h3>log4j配置示例</h3>

<p>配置好executor的log4j配置文件，命名随意，假设为executor-log4j.properties，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlog4j.configuration=executor-log4j.properties
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-log4j.properties xxx
则作业运行时的日志级别将由executor-log4j.properties文件控制。
</code></pre>

<h3>logback配置示例</h3>

<p>配置好executor的logback配置文件，命名随意，假设为executor-logback.xml，放在conf目录下。</p>

<p>配置spark-conf.defaults文件，在 spark.executor.extraJavaOptions 中增加:</p>

<pre><code class="bash">spark.executor.extraJavaOptions -Dlogback.configurationFile=executor-logback.xml
</code></pre>

<p>启动Spark作业时增加–files参数。</p>

<pre><code class="bash">$spark-submit --files /path/to/conf/executor-logback.xml xxx
</code></pre>

<p>则作业运行时的日志级别将由executor-logback.xml文件控制。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spark HistoryServer 配置和使用方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2016/08/24/spark-historyserver-configuration/"/>
    <updated>2016-08-24T17:17:58+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2016/08/24/spark-historyserver-configuration</id>
    <content type="html"><![CDATA[<p>本文介绍Spark History Server的配置和使用方法。</p>

<!--More-->


<h2>History Server 配置</h2>

<p>Spark提供了History Server服务可以保存历史Application的运行记录。</p>

<h3>客户端配置</h3>

<p>对于提交应用程序的客户端需要在conf/spark-defaults.conf中配置以下参数：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.eventLog.enabled      </td>
<td style="text-align:left;"> 是否记录Spark事件，用于应用程序在完成后重构webUI。 </td>
</tr>
<tr>
<td> spark.eventLog.dir      </td>
<td style="text-align:left;"> spark.eventLog.enabled为 true，该属性为记录spark事件的根目录。在此根目录中，Spark为每个应用程序创建分目录，并将应用程序的事件记录到此目录中。<br>可以将此属性设置为HDFS目录，以便history server读取历史记录文件。</br>      </td>
</tr>
<tr>
<td> spark.yarn.historyServer.address </td>
<td style="text-align:left;"> Spark history server的地址。 这个地址会在Spark应用程序完成后提交给YARN RM，然后RM将信息从RM UI写到history server UI上。<br><strong><font color=red>注意：hostname:port，前面不加http：//，末尾也不要加反斜杠。</font></strong> </br>     </td>
</tr>
</tbody>
</table>


<h3>服务端配置</h3>

<p>服务端主要需要在conf/spark-defaults.conf中配置如下属性：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
<th style="text-align:left;"> 默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.history.ui.port     </td>
<td style="text-align:left;"> History Server的默认访问端口。<strong><font color=red>建议配置在8000~9000之间，以确保再内网浏览器能够正常显示。</strong><font color=red> </td>
<td style="text-align:left;"> 18080 </td>
</tr>
<tr>
<td> spark.history.fs.logDirectory    </td>
<td style="text-align:left;">   用于指定HistoryServer读取的eventlog存放的hdfs路径。  </td>
<td style="text-align:left;">无</td>
</tr>
<tr>
<td> spark.history.updateInterval </td>
<td style="text-align:left;">  History Server显示信息的刷新时间间隔，以秒为单位。每次更新都会检查持久层事件日志的任何变化。  </td>
<td style="text-align:left;"> 10 </td>
</tr>
<tr>
<td>spark.history.retainedApplications</td>
<td style="text-align:left;">在History Server上显示的最大应用程序数量，如果超过这个值，旧的应用程序信息将被删除。</td>
<td style="text-align:left;">250</td>
</tr>
</tbody>
</table>


<p>如果使用Kerberos认证可以配置如下参数：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
<th style="text-align:left;"> 默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td> spark.history.kerberos.enabled    </td>
<td style="text-align:left;"> 是否使用kerberos方式登录访问history server。</td>
<td style="text-align:left;">false</td>
</tr>
<tr>
<td>spark.history.kerberos.principal</td>
<td style="text-align:left;">spark.history.kerberos.enabled为true时使用，用于指定History Server的kerberos主体名称</td>
<td style="text-align:left;">空</td>
</tr>
<tr>
<td>spark.history.kerberos.keytab</td>
<td style="text-align:left;">spark.history.kerberos.enabled为true时使用，用于指定History Server的kerberos keytab文件位置</td>
<td style="text-align:left;">空</td>
</tr>
<tr>
<td>spark.history.ui.acls.enable</td>
<td style="text-align:left;">授权用户查看应用程序信息的时候是否检查acl。如果启用，无论应用程序的spark.ui.acls.enable怎么设置，都要进行授权检查。<br>只有应用程序所有者和spark.ui.view.acls指定的用户可以查看应用程序信息; 如果禁用，不做任何检查。</br></td>
<td style="text-align:left;">false</td>
</tr>
</tbody>
</table>


<p>另外，服务端可以配置以下环境变量：</p>

<table>
<thead>
<tr>
<th> 参数        </th>
<th style="text-align:left;"> 功能           </th>
</tr>
</thead>
<tbody>
<tr>
<td>SPARK_DAEMON_JAVA_OPTS</td>
<td style="text-align:left;">History Server的JVM参数，默认为空</td>
</tr>
<tr>
<td>SPARK_DAEMON_MEMORY</td>
<td style="text-align:left;">分配给History Server的内存大小，默认512M</td>
</tr>
<tr>
<td>SPARK_HISTORY_OPTS</td>
<td style="text-align:left;">History Server的属性设置，默认为空。</td>
</tr>
<tr>
<td>SPARK_PUBLIC_DNS</td>
<td style="text-align:left;">History Server的公网地址，如果不设置，可以用内网地址来访问，默认为空。</td>
</tr>
</tbody>
</table>


<h2>History Server 使用</h2>

<h3>启动</h3>

<p>一般将客户端运行生成的eventlog统一存放在一个HDFS路径下便于查询历史记录，然后History Server端 spark.history.fs.logDirectory的值设为该路径即可。</p>

<p>启动History Server命令：</p>

<pre><code>$sh sbin/start-history-server.sh
</code></pre>

<h3>停止</h3>

<p>停止History Server命令：</p>

<pre><code>$sh sbin/stop-history-server.sh
</code></pre>
]]></content>
  </entry>
  
</feed>
