<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[技术资源 | Workspace of LionHeart]]></title>
  <link href="http://lionheartwang.github.io/blog/categories/技术资源/atom.xml" rel="self"/>
  <link href="http://lionheartwang.github.io/"/>
  <updated>2017-11-14T00:21:06+08:00</updated>
  <id>http://lionheartwang.github.io/</id>
  <author>
    <name><![CDATA[Wang Yiguang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[使用Fuse挂载HDFS到本地目录方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/11/14/gua-zai-hdfsdao-ben-di-mu-lu-fang-fa/"/>
    <updated>2017-11-14T00:10:27+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/11/14/gua-zai-hdfsdao-ben-di-mu-lu-fang-fa</id>
    <content type="html"><![CDATA[<p>网上关于挂载HDFS到本地的介绍大多基于较早版本的Hadoop。
本文以Hadoop-2.8.0为例，介绍通过Fuse挂载HDFS到本地的方法。</p>

<!--more-->


<h2>安装Fuse</h2>

<p>对每台节点，执行如下命令一键安装</p>

<pre><code class="bash">sudo yum -y install fuse fuse-libs
</code></pre>

<h2>编译fuse-dfs工具</h2>

<p>下载hadoop-2.8.0源码，解压编译</p>

<pre><code class="bash">tar zxvf hadoop-2.8.0.tar.gz
cd hadoop-2.8.0
mvn package -Drequire.fuse=true -DskipTests -Dmaven.javadoc.skip=true -Dtar
</code></pre>

<p>编译后会生成fuse_dfs的可执行文件，位于</p>

<blockquote><p>./hadoop-hdfs-project/hadoop-hdfs-native-client/target/main/native/fuse-dfs/fuse_dfs</p></blockquote>

<p>另外会生成一个对该可执行程序的封装脚本，位于</p>

<blockquote><p>./hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_dfs_wrapper.sh</p></blockquote>

<h2>配置环境变量</h2>

<p>可以为fuse_dfs_wrapper.sh建立软链接到当前目录方便后续使用。</p>

<pre><code class="bash">ln -s /&lt;Hadoop源码路径&gt;/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_dfs_wrapper.sh .
</code></pre>

<p>编辑fuse_dfs_wrapper.sh内容，有一些需要根据具体情况修改：</p>

<pre><code class="bash">HADOOP_HOME=/path/to/your/hadoop
HADOOP_PREFIX=/path/to/your/hadoop/src/

export FUSEDFS_PATH="$HADOOP_PREFIX/hadoop-hdfs-project/hadoop-hdfs-native-client/target/main/native/fuse-dfs"
export LIBHDFS_PATH="$HADOOP_PREFIX/hadoop-hdfs-project/hadoop-hdfs-native-client/target/native/target/usr/local/lib"
HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

if [ "$OS_ARCH" = "" ]; then
  export OS_ARCH=amd64
fi

# 这里需要替换为JDK的安装路径
JAVA_HOME=/home/yiguang.wyg/tools/jdk1.8.0_121

if [ "$LD_LIBRARY_PATH" = "" ]; then
  export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/$OS_ARCH/server:/usr/local/lib
fi

JARS=`find "$HADOOP_PREFIX/hadoop-hdfs-project" -name "*.jar" | xargs`
for jar in $JARS; do
  CLASSPATH=$jar:$CLASSPATH
done

JARS=`find "$HADOOP_PREFIX/hadoop-client" -name "*.jar" | xargs`
for jar in $JARS; do
  CLASSPATH=$jar:$CLASSPATH
done

export CLASSPATH=$HADOOP_CONF_DIR:$CLASSPATH
export PATH=$FUSEDFS_PATH:$PATH
export LD_LIBRARY_PATH=$LIBHDFS_PATH:$JAVA_HOME/jre/lib/$OS_ARCH/server:$LD_LIBRARY_PATH

fuse_dfs "$@"
</code></pre>

<p>重点需要配置好HADOOP_HOME和HADOOP_PREFIX，分别为hadoop安装路径和hadoop源码路径。</p>

<h2>挂载HDFS</h2>

<p>挂载HDFS之前需要确保HDFS已经启动。</p>

<p>创建挂载目录</p>

<pre><code class="bash">sudo mkdir /mnt/hdfs
</code></pre>

<p>执行：</p>

<pre><code class="bash">sudo sh fuse_dfs_wrapper.sh hdfs://&lt;hdfs路径&gt; /mnt/hdfs
</code></pre>

<p>输出：</p>

<blockquote><p>INFO /&hellip;/hadoop-2.8.0-src/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/fuse-dfs/fuse_options.c:164 Adding FUSE arg /mnt/hdfs</p></blockquote>

<p>进入挂载目录，如果能访问到HDFS中的内容，说明挂载成功。
<code>
cd /mnt/hdfs
ls
</code></p>

<p>挂载成功后，就可以将HDFS当做本地路径使用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux NFS配置及使用方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/10/24/linux-nfs-configuration/"/>
    <updated>2017-10-24T00:27:55+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/10/24/linux-nfs-configuration</id>
    <content type="html"><![CDATA[<p>NFS是Network  File System（网络文件系统）。主要功能是通过网络让不同的服务器之间可以共享文件或者目录。</p>

<p>本文以CentOS系统为例介绍Linux下NFS的配置和使用方法。</p>

<p>NFS在文件传送过程中依赖与RPC（远程过程调用）协议，配置步骤介绍如下。</p>

<!-- more -->


<h2>安装软件包</h2>

<p>安装nfs软件包，server和client机器都需要安装</p>

<pre><code class="bash">sudo yum -y install nfs-utils nfs-utils-lib
</code></pre>

<h2>配置NFS Server</h2>

<p>假设用来共享目录的NFS Server机器是192.168.0.1，需要登录该机器配置挂载目录。</p>

<p>登录后编辑/etc/exports文件内容，输入需要挂载的机器IP，以及服务端共享的路径。</p>

<p>假设需要访问NFS共享目录的机器为192.168.0.2 ~ 192.168.0.6，配置/etc/exports如下所示：</p>

<pre><code>/path/to/mount 192.168.0.2(rw,sync,no_root_squash)
/path/to/mount 192.168.0.3(rw,sync,no_root_squash)
/path/to/mount 192.168.0.4(rw,sync,no_root_squash)
/path/to/mount 192.168.0.5(rw,sync,no_root_squash)
/path/to/mount 192.168.0.6(rw,sync,no_root_squash)
...
</code></pre>

<p>其中/path/to/mount根据需要配置为欲挂载的路径即可。</p>

<h2>启动NFS Server</h2>

<p>在192.168.0.1上执行如下命令启动NFS Server</p>

<pre><code class="bash">sudo service rpcbind restart
sudo service nfs restart
</code></pre>

<p>执行如下命令，则会显示挂载的机器IP列表：</p>

<pre><code class="bash">showmount -e 192.168.0.1
</code></pre>

<h2>配置NFS Client</h2>

<p>分别登陆每台需要挂载的client机器，运行如下命令进行共享文件夹挂载。</p>

<pre><code>sudo mkdir /target/to/mount
sudo mount -t nfs 192.168.0.1:/path/to/mount /target/to/mount
</code></pre>

<p>其中：</p>

<ul>
<li>/path/to/mount为之前配置的NFS Server上挂载的路径。</li>
<li>/target/to/mount为本地机器欲挂载到的目标路径。</li>
</ul>


<p>挂载完成后，在192.168.0.2 ~ 192.168.0.6上就可以向访问本地路径一样访问192.168.0.1的/path/to/mount目录了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker常用命令介绍]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/06/18/dockerchang-yong-ming-ling-jie-shao/"/>
    <updated>2017-06-18T22:52:05+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/06/18/dockerchang-yong-ming-ling-jie-shao</id>
    <content type="html"><![CDATA[<p>本文介绍常用的docker命令。</p>

<!--more-->


<h2>镜像相关</h2>

<p>查看本地具有的镜像</p>

<pre><code>sudo docker images
</code></pre>

<p>登录远程镜像仓库</p>

<pre><code>docker login &lt;镜像仓库地址&gt;
</code></pre>

<p>例如：</p>

<blockquote><p>docker login test.lionheart.com</p></blockquote>

<p>命名镜像</p>

<pre><code class="bash">docker tag &lt;镜像id&gt; &lt;镜像仓库地址&gt;/&lt;镜像空间名&gt;/&lt;镜像名&gt;:&lt;镜像tag&gt;
</code></pre>

<p>命名镜像后可推送镜像到远端仓库：</p>

<pre><code class="bash">docker push &lt;镜像仓库地址&gt;/&lt;镜像空间名&gt;/&lt;镜像名&gt;:&lt;镜像tag&gt;
</code></pre>

<p>例如：</p>

<blockquote><p>docker tag 12ab34cd56ef test.lionheart.com/wangyiguang/dockertest:1.0</p>

<p>docker push test.lionheart.com/wangyiguang/dockertest:1.0</p></blockquote>

<h2>容器相关</h2>

<p>启动container：</p>

<pre><code class="bash">sudo docker run -tid --name &lt;镜像名&gt; --net=host -l "&lt;资源配置&gt;" &lt;镜像id&gt; /bin/bash
</code></pre>

<p>示例：</p>

<blockquote><p>sudo docker run -tid &ndash;name lionhearttest &ndash;net=host  \</p>

<p>-l &ldquo;GpuCount=1&rdquo; -l &ldquo;PerGpuCache=100000&rdquo; 12ab34cd56ef /bin/bash</p></blockquote>

<p>查看所有container：</p>

<pre><code class="bash">sudo docker ps -a
</code></pre>

<pre><code class="bash">docker tag image_id $image_center_addr/$image_namespace/$IMAGE_NAME:$TAG
</code></pre>

<p>以当前容器创建镜像：</p>

<pre><code class="bash">sudo docker commit &lt;容器id&gt; &lt;镜像名&gt;
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用InteliJ远程调试程序]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/04/17/remote-debug-via-intelij/"/>
    <updated>2017-04-17T18:50:33+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/04/17/remote-debug-via-intelij</id>
    <content type="html"><![CDATA[<p>本文介绍如何使用InteliJ远程调试Java/Scala程序。</p>

<!--more-->


<h2>以调试模式启动程序</h2>

<p>JVM添加如下启动参数：</p>

<pre><code class="bash">JAVA_DEBUG_OPTS="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=&lt;debugPort&gt;"
java $JAVA_DEBUG_OPTS &lt;className&gt;
</code></pre>

<p>其中：</p>

<ul>
<li>debugPort为调试服务端口，供InteliJ调试器连接，后面会用到。</li>
<li>className为待执行的程序类。</li>
</ul>


<p>启动后会提示如下信息：</p>

<blockquote><p>Listening for transport dt_socket at address: xxxx</p></blockquote>

<h2>调试器远程连接</h2>

<p>在InteliJ菜单选择<code>Run</code> -> <code>Edit Configuration</code>，进入运行配置界面。</p>

<p>选择<code>+</code>添加一项新的配置，内容如下图所示：</p>

<p><img src="/images/blog/04-remoteDebug01.png"></p>

<p>填好配置名称，IP、端口即可。IP、端口要和之前远程启动的程序一致。</p>

<p>然后就可以在源码中设置断点，在InteliJ中进行调试了。</p>

<p><img src="/images/blog/05-remoteDebug02.png"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mac安装Thrift方法]]></title>
    <link href="http://lionheartwang.github.io/blog/2017/03/14/intall-thrift-on-mac/"/>
    <updated>2017-03-14T17:25:31+08:00</updated>
    <id>http://lionheartwang.github.io/blog/2017/03/14/intall-thrift-on-mac</id>
    <content type="html"><![CDATA[<p>新版mac使用brew默认安装的是最新版本的thrift 0.10.1</p>

<p>但现有项目主要依赖0.9.x，因此需要在mac上手动安装thrift。</p>

<p>本文介绍如何在新版本Mac上安装thrift 0.9.3.</p>

<!--more-->


<h2>安装依赖</h2>

<p>确保安装了如下依赖：</p>

<ul>
<li>openssl</li>
<li>libevent</li>
<li>bison 版本> 2.5</li>
</ul>


<p>注意：</p>

<p>mac高版本安装openssl之后可能提示openssl为keg-only的版本</p>

<p>需要记下其安装目录，默认为/usr/local/opt/openssl.</p>

<h2>下载thrift</h2>

<p>以0.9.3为例：</p>

<pre><code class="bash">$wget http://archive.apache.org/dist/thrift/0.9.3/thrift-0.9.3.tar.gz
</code></pre>

<p>下载后解压：</p>

<pre><code class="bash">$tar zxvf thrift-0.9.3.tar.gz
</code></pre>

<h2>编译安装thrift</h2>

<p>运行configure进行配置，注意这里指定了前面记下的openssl的路径：</p>

<pre><code class="bash">$./configure --with-openssl=/usr/local/opt/openssl --without-perl --without-php
</code></pre>

<p>编译：</p>

<pre><code class="bash">$./make
</code></pre>

<p>安装：</p>

<pre><code class="bash">$./make install
</code></pre>

<p>安装后运行：</p>

<pre><code class="bash">$thrift --version
</code></pre>

<p>输出：Thrift version 0.9.3</p>

<p>表明<font color=green><b>安装成功</b></font>。</p>
]]></content>
  </entry>
  
</feed>
